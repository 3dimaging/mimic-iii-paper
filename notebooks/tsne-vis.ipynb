{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of the MIMIC data using t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a background on t-Distributed Stochastic Neighbor Embedding (t-SNE), see Laurens van der Maaten's blog: https://lvdmaaten.github.io/tsne/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# config\n",
    "# for speed, run on a subset of 5000 patient\n",
    "run_on_subset = False\n",
    "# should the proportion of each class be equalized?\n",
    "balanceclasses = False \n",
    "# Random state.\n",
    "randomstate = 9324503\n",
    "# Scale columns with zero mean and unit variance\n",
    "scaleinput = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import psycopg2\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TSNE in module sklearn.manifold.t_sne:\n",
      "\n",
      "class TSNE(sklearn.base.BaseEstimator)\n",
      " |  t-distributed Stochastic Neighbor Embedding.\n",
      " |  \n",
      " |  t-SNE [1] is a tool to visualize high-dimensional data. It converts\n",
      " |  similarities between data points to joint probabilities and tries\n",
      " |  to minimize the Kullback-Leibler divergence between the joint\n",
      " |  probabilities of the low-dimensional embedding and the\n",
      " |  high-dimensional data. t-SNE has a cost function that is not convex,\n",
      " |  i.e. with different initializations we can get different results.\n",
      " |  \n",
      " |  It is highly recommended to use another dimensionality reduction\n",
      " |  method (e.g. PCA for dense data or TruncatedSVD for sparse data)\n",
      " |  to reduce the number of dimensions to a reasonable amount (e.g. 50)\n",
      " |  if the number of features is very high. This will suppress some\n",
      " |  noise and speed up the computation of pairwise distances between\n",
      " |  samples. For more tips see Laurens van der Maaten's FAQ [2].\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int, optional (default: 2)\n",
      " |      Dimension of the embedded space.\n",
      " |  \n",
      " |  perplexity : float, optional (default: 30)\n",
      " |      The perplexity is related to the number of nearest neighbors that\n",
      " |      is used in other manifold learning algorithms. Larger datasets\n",
      " |      usually require a larger perplexity. Consider selcting a value\n",
      " |      between 5 and 50. The choice is not extremely critical since t-SNE\n",
      " |      is quite insensitive to this parameter.\n",
      " |  \n",
      " |  early_exaggeration : float, optional (default: 4.0)\n",
      " |      Controls how tight natural clusters in the original space are in\n",
      " |      the embedded space and how much space will be between them. For\n",
      " |      larger values, the space between natural clusters will be larger\n",
      " |      in the embedded space. Again, the choice of this parameter is not\n",
      " |      very critical. If the cost function increases during initial\n",
      " |      optimization, the early exaggeration factor or the learning rate\n",
      " |      might be too high.\n",
      " |  \n",
      " |  learning_rate : float, optional (default: 1000)\n",
      " |      The learning rate can be a critical parameter. It should be\n",
      " |      between 100 and 1000. If the cost function increases during initial\n",
      " |      optimization, the early exaggeration factor or the learning rate\n",
      " |      might be too high. If the cost function gets stuck in a bad local\n",
      " |      minimum increasing the learning rate helps sometimes.\n",
      " |  \n",
      " |  n_iter : int, optional (default: 1000)\n",
      " |      Maximum number of iterations for the optimization. Should be at\n",
      " |      least 200.\n",
      " |  \n",
      " |  metric : string or callable, optional\n",
      " |      The metric to use when calculating distance between instances in a\n",
      " |      feature array. If metric is a string, it must be one of the options\n",
      " |      allowed by scipy.spatial.distance.pdist for its metric parameter, or\n",
      " |      a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix.\n",
      " |      Alternatively, if metric is a callable function, it is called on each\n",
      " |      pair of instances (rows) and the resulting value recorded. The callable\n",
      " |      should take two arrays from X as input and return a value indicating\n",
      " |      the distance between them. The default is \"euclidean\" which is\n",
      " |      interpreted as squared euclidean distance.\n",
      " |  \n",
      " |  init : string, optional (default: \"random\")\n",
      " |      Initialization of embedding. Possible options are 'random' and 'pca'.\n",
      " |      PCA initialization cannot be used with precomputed distances and is\n",
      " |      usually more globally stable than random initialization.\n",
      " |  \n",
      " |  verbose : int, optional (default: 0)\n",
      " |      Verbosity level.\n",
      " |  \n",
      " |  random_state : int or RandomState instance or None (default)\n",
      " |      Pseudo Random Number generator seed control. If None, use the\n",
      " |      numpy.random singleton. Note that different initializations\n",
      " |      might result in different local minima of the cost function.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  embedding_ : array-like, shape (n_samples, n_components)\n",
      " |      Stores the embedding vectors.\n",
      " |  \n",
      " |  training_data_ : array-like, shape (n_samples, n_features)\n",
      " |      Stores the training data.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.manifold import TSNE\n",
      " |  >>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
      " |  >>> model = TSNE(n_components=2, random_state=0)\n",
      " |  >>> model.fit_transform(X) # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n",
      " |  array([[  887.28...,   238.61...],\n",
      " |         [ -714.79...,  3243.34...],\n",
      " |         [  957.30..., -2505.78...],\n",
      " |         [-1130.28...,  -974.78...])\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  [1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data\n",
      " |      Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.\n",
      " |  \n",
      " |  [2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding\n",
      " |      http://homepage.tudelft.nl/19j49/t-SNE.html\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TSNE\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=2, perplexity=30.0, early_exaggeration=4.0, learning_rate=1000.0, n_iter=1000, metric='euclidean', init='random', verbose=0, random_state=None)\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit the model using X as training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array, shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          If the metric is 'precomputed' X must be a square distance\n",
      " |          matrix. Otherwise it contains a sample per row.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Transform X to the embedded space.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array, shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          If the metric is 'precomputed' X must be a square distance\n",
      " |          matrix. Otherwise it contains a sample per row.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape (n_samples, n_components)\n",
      " |          Embedding of the training data in low-dimensional space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display TSNE documentation\n",
    "help(TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to MIMIC\n",
    "sqluser = 'postgres'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to ' + schema_name)\n",
    "# cur.close()\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH firstvals as (\n",
    "    SELECT rank() OVER (PARTITION BY vi.subject_id ORDER BY ic.intime ASC) as icuorder,\n",
    "    vi.*, ic.intime, di.icd9_code, dd.short_title, ic.los_icu, ic.hospital_expire_flag,\n",
    "    ic.los_hospital, ic.age, ic.gender, an.angus,\n",
    "    el.congestive_heart_failure, el.cardiac_arrhythmias,el.valvular_disease,el.pulmonary_circulation,\n",
    "    el.peripheral_vascular,el.hypertension,el.paralysis,el.other_neurological,el.chronic_pulmonary,\n",
    "    el.diabetes_uncomplicated,el.diabetes_complicated,el.hypothyroidism,el.renal_failure,el.liver_disease,\n",
    "    el.peptic_ulcer,el.aids,el.lymphoma,el.metastatic_cancer,el.solid_tumor,el.rheumatoid_arthritis,\n",
    "    el.coagulopathy,el.obesity,el.weight_loss,el.fluid_electrolyte,el.blood_loss_anemia,\n",
    "    el.deficiency_anemias,el.alcohol_abuse,el.drug_abuse,el.psychoses,el.depression\n",
    "    FROM vitalsfirstday vi\n",
    "    INNER JOIN diagnoses_icd di\n",
    "    ON vi.hadm_id = di.hadm_id\n",
    "    INNER JOIN d_icd_diagnoses dd\n",
    "    ON di.icd9_code = dd.icd9_code\n",
    "    INNER JOIN icustay_detail ic\n",
    "    ON vi.icustay_id = ic.icustay_id\n",
    "    INNER JOIN elixhauser_ahrq el\n",
    "    ON vi.hadm_id = el.hadm_id\n",
    "    INNER JOIN angus_sepsis an\n",
    "    ON vi.hadm_id = an.hadm_id \n",
    "    WHERE di.seq_num = 1\n",
    "    ORDER BY vi.subject_id)\n",
    "SELECT *\n",
    "FROM firstvals\n",
    "WHERE age >=16\n",
    "AND los_icu >=1\n",
    "\"\"\"\n",
    "\n",
    "phys = pd.read_sql_query(query,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Encode gender\n",
    "phys['gender'] = pd.factorize(phys['gender'])[0]\n",
    "phys['icd9_code_enc'] = pd.factorize(phys['icd9_code'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Limit the dataset for speed\n",
    "if run_on_subset:\n",
    "    n_to_compute=5000\n",
    "    phys = phys[:n_to_compute]\n",
    "    print('Running on limited subset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vars of interest\n",
    "\n",
    "# physvars = ['heartrate_min', 'heartrate_max', 'sysbp_min', 'sysbp_max', 'diasbp_min', 'diasbp_max', 'meanbp_min', \n",
    "#             'meanbp_max', 'resprate_min', 'resprate_max', 'tempc_min', 'tempc_max', 'spo2_min', 'spo2_max', \n",
    "#             'glucose_min', 'glucose_max']\n",
    "\n",
    "# physvars = ['heartrate_mean', 'sysbp_mean', 'diasbp_mean', 'meanbp_mean', \n",
    "#             'resprate_mean', 'tempc_mean', 'spo2_mean', 'glucose_mean'] \n",
    "\n",
    "physvars = ['heartrate_min', 'heartrate_max', 'sysbp_min', 'sysbp_max', 'diasbp_min', 'diasbp_max', 'meanbp_min', \n",
    "            'meanbp_max', 'resprate_min', 'resprate_max', 'tempc_min', 'tempc_max', 'spo2_min', 'spo2_max', \n",
    "            'glucose_min', 'glucose_max', 'heartrate_mean', 'sysbp_mean', 'diasbp_mean', 'meanbp_mean', \n",
    "            'resprate_mean', 'tempc_mean', 'spo2_mean', 'glucose_mean'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows with nan\n",
    "phys.dropna(inplace=True, subset=physvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale columns with zero mean and unit variance\n",
    "if scaleinput: \n",
    "    print('Columns scaled with with zero mean and unit variance.')\n",
    "    phys[physvars] = MinMaxScaler().fit_transform(phys[physvars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the tsne\n",
    "X_tsne = TSNE(learning_rate=1000,random_state=354235).fit_transform(phys[physvars].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add X_tsne to phys dataframe\n",
    "phys['X_tsne1'] = X_tsne[:, 0]\n",
    "phys['X_tsne2'] = X_tsne[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define label for colouring plot\n",
    "# phys['label']=phys.gender\n",
    "# phys['label']=phys.weight_loss*6\n",
    "# phys['label']=phys.angus*6\n",
    "phys['label']=phys.hospital_expire_flag*6\n",
    "# phys['label']=pd.qcut(phys.los_hospital,11,labels=range(1,12))\n",
    "# phys['label']=pd.qcut(phys.los_icu,8,labels=range(0,8))\n",
    "# phys['label']=pd.qcut(phys.icd9_code_enc,9,labels=range(0,9))\n",
    "# phys['label']=pd.qcut(phys.age,10,labels=range(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# balance selection of classes with weight vector\n",
    "if balanceclasses:\n",
    "    labelcount=phys.label.value_counts(normalize=True)\n",
    "    phys['labelweight']=np.ones(len(phys))\n",
    "    for la,wt in labelcount.iteritems():\n",
    "        phys.loc[phys.label==la,'labelweight'] = 1-wt\n",
    "    # get sample approx equal classes\n",
    "    totalnum=phys.label.value_counts().min()*phys.label.nunique()\n",
    "    # sample with replacement when balancing classes\n",
    "    samplewithreplace = False\n",
    "    phys = phys.sample(n=totalnum, replace=samplewithreplace, weights=phys.labelweight)\n",
    "    print('Class numbers balanced')\n",
    "print('Number of classes: {}'.format(phys.label.nunique()))\n",
    "print('Number of samples: {}'.format(phys.label.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set colours for plot\n",
    "# \"Tableau 20\" colors as RGB.   \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "col = np.array(tableau20)[[phys.label]]\n",
    "plt.scatter(phys['X_tsne1'], phys['X_tsne2'], \n",
    "            facecolor=col, edgecolor='None', marker='o', s=50,\n",
    "            alpha=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
